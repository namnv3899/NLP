{"cells":[{"cell_type":"code","execution_count":14,"id":"yU2AEK8ffvzt","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3386,"status":"ok","timestamp":1642398029628,"user":{"displayName":"Long Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhVMJhKk7_VigZ2kWKxtT_FSssrLz13ITPlt2q2=s64","userId":"04407739074008177889"},"user_tz":-420},"id":"yU2AEK8ffvzt","outputId":"1997506a-6ff9-492c-f8c2-f96a7b105998"},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'google.colab'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_12632/1408506528.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n"]},{"cell_type":"code","execution_count":null,"id":"I5jK4FAmgFd5","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3302,"status":"ok","timestamp":1642397245136,"user":{"displayName":"Long Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhVMJhKk7_VigZ2kWKxtT_FSssrLz13ITPlt2q2=s64","userId":"04407739074008177889"},"user_tz":-420},"id":"I5jK4FAmgFd5","outputId":"07ea4e03-4e0a-47d6-e5c9-47ca04e69ad6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into 'NLP'...\n","remote: Enumerating objects: 63, done.\u001b[K\n","remote: Counting objects: 100% (63/63), done.\u001b[K\n","remote: Compressing objects: 100% (50/50), done.\u001b[K\n","remote: Total 63 (delta 10), reused 60 (delta 9), pack-reused 0\u001b[K\n","Unpacking objects: 100% (63/63), done.\n"]}],"source":["!git clone https: // github.com/namnv3899/NLP.git\n"]},{"cell_type":"code","execution_count":null,"id":"a2BtOJrwfwyi","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":11081,"status":"ok","timestamp":1642397597190,"user":{"displayName":"Long Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhVMJhKk7_VigZ2kWKxtT_FSssrLz13ITPlt2q2=s64","userId":"04407739074008177889"},"user_tz":-420},"id":"a2BtOJrwfwyi","outputId":"7c929b0d-bdaa-44be-c522-cd55f61ee1cf"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting vncorenlp\n","  Downloading vncorenlp-1.0.3.tar.gz (2.6 MB)\n","\u001b[K     |████████████████████████████████| 2.6 MB 8.3 MB/s \n","\u001b[?25hCollecting transformers\n","  Downloading transformers-4.15.0-py3-none-any.whl (3.4 MB)\n","\u001b[K     |████████████████████████████████| 3.4 MB 71.1 MB/s \n","\u001b[?25hCollecting fairseq\n","  Downloading fairseq-0.10.2-cp37-cp37m-manylinux1_x86_64.whl (1.7 MB)\n","\u001b[K     |████████████████████████████████| 1.7 MB 62.9 MB/s \n","\u001b[?25hRequirement already satisfied: seaborn in /usr/local/lib/python3.7/dist-packages (0.11.2)\n","Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (0.0)\n","Requirement already satisfied: wordcloud in /usr/local/lib/python3.7/dist-packages (1.5.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from vncorenlp) (2.23.0)\n","Collecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 76.0 MB/s \n","\u001b[?25hCollecting sacremoses\n","  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 58.3 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.2)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n","\u001b[K     |████████████████████████████████| 67 kB 5.5 MB/s \n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.10.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 55.4 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n","Collecting sacrebleu>=1.4.12\n","  Downloading sacrebleu-2.0.0-py3-none-any.whl (90 kB)\n","\u001b[K     |████████████████████████████████| 90 kB 13.0 MB/s \n","\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from fairseq) (1.10.0+cu111)\n","Collecting dataclasses\n","  Downloading dataclasses-0.6-py3-none-any.whl (14 kB)\n","Collecting hydra-core\n","  Downloading hydra_core-1.1.1-py3-none-any.whl (145 kB)\n","\u001b[K     |████████████████████████████████| 145 kB 84.0 MB/s \n","\u001b[?25hRequirement already satisfied: cffi in /usr/local/lib/python3.7/dist-packages (from fairseq) (1.15.0)\n","Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from fairseq) (0.29.26)\n","Collecting colorama\n","  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n","Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu>=1.4.12->fairseq) (0.8.9)\n","Collecting portalocker\n","  Downloading portalocker-2.3.2-py2.py3-none-any.whl (15 kB)\n","Requirement already satisfied: matplotlib>=2.2 in /usr/local/lib/python3.7/dist-packages (from seaborn) (3.2.2)\n","Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.7/dist-packages (from seaborn) (1.4.1)\n","Requirement already satisfied: pandas>=0.23 in /usr/local/lib/python3.7/dist-packages (from seaborn) (1.1.5)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn) (0.11.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn) (2.8.2)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn) (1.3.2)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23->seaborn) (2018.9)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=2.2->seaborn) (1.15.0)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn) (1.0.2)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from wordcloud) (7.1.2)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi->fairseq) (2.21)\n","Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from hydra-core->fairseq) (5.4.0)\n","Collecting antlr4-python3-runtime==4.8\n","  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n","\u001b[K     |████████████████████████████████| 112 kB 78.1 MB/s \n","\u001b[?25hCollecting omegaconf==2.1.*\n","  Downloading omegaconf-2.1.1-py3-none-any.whl (74 kB)\n","\u001b[K     |████████████████████████████████| 74 kB 4.3 MB/s \n","\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->vncorenlp) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->vncorenlp) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->vncorenlp) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->vncorenlp) (1.24.3)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (3.0.0)\n","Building wheels for collected packages: vncorenlp, antlr4-python3-runtime\n","  Building wheel for vncorenlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for vncorenlp: filename=vncorenlp-1.0.3-py3-none-any.whl size=2645951 sha256=417c9642692abe8086e284e290af5c94bc8347307a0e352971342add83ce771c\n","  Stored in directory: /root/.cache/pip/wheels/0c/d8/f2/d28d97379b4f6479bf51247c8dfd57fa00932fa7a74b6aab29\n","  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141230 sha256=dd017c7808611ebd8e7b573794d26a7ed83b7859b55f4213cbb202ff22318f76\n","  Stored in directory: /root/.cache/pip/wheels/ca/33/b7/336836125fc9bb4ceaa4376d8abca10ca8bc84ddc824baea6c\n","Successfully built vncorenlp antlr4-python3-runtime\n","Installing collected packages: pyyaml, antlr4-python3-runtime, portalocker, omegaconf, colorama, tokenizers, sacremoses, sacrebleu, hydra-core, huggingface-hub, dataclasses, vncorenlp, transformers, fairseq\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed antlr4-python3-runtime-4.8 colorama-0.4.4 dataclasses-0.6 fairseq-0.10.2 huggingface-hub-0.4.0 hydra-core-1.1.1 omegaconf-2.1.1 portalocker-2.3.2 pyyaml-6.0 sacrebleu-2.0.0 sacremoses-0.0.47 tokenizers-0.10.3 transformers-4.15.0 vncorenlp-1.0.3\n"]},{"data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["pydevd_plugins"]}}},"metadata":{},"output_type":"display_data"}],"source":["!pip install vncorenlp transformers fairseq seaborn sklearn wordcloud\n"]},{"cell_type":"code","execution_count":null,"id":"1nzm3rfJsjqX","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2272,"status":"ok","timestamp":1642400490637,"user":{"displayName":"Long Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhVMJhKk7_VigZ2kWKxtT_FSssrLz13ITPlt2q2=s64","userId":"04407739074008177889"},"user_tz":-420},"id":"1nzm3rfJsjqX","outputId":"5c2a1f79-46b5-47b6-b081-fa899467a431"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into 'phobert-base'...\n","remote: Enumerating objects: 36, done.\u001b[K\n","remote: Counting objects: 100% (36/36), done.\u001b[K\n","remote: Compressing objects: 100% (35/35), done.\u001b[K\n","remote: Total 36 (delta 14), reused 0 (delta 0)\u001b[K\n","Unpacking objects: 100% (36/36), done.\n"]}],"source":["!git clone https: // huggingface.co/vinai/phobert-base\n"]},{"cell_type":"code","execution_count":1,"id":"greater-share","metadata":{"ExecuteTime":{"end_time":"2021-04-05T15:49:35.358178Z","start_time":"2021-04-05T15:49:33.826424Z"},"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6293,"status":"ok","timestamp":1642401494238,"user":{"displayName":"Long Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhVMJhKk7_VigZ2kWKxtT_FSssrLz13ITPlt2q2=s64","userId":"04407739074008177889"},"user_tz":-420},"id":"greater-share","outputId":"989ee489-8b9a-4d16-c84d-dbc6253d78db"},"outputs":[{"name":"stderr","output_type":"stream","text":["2022-01-19 09:40:26.735790: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n"]}],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from wordcloud import WordCloud\n","import pickle\n","from utils import load_yaml, timing\n","from nlp import NLP\n","from training import *\n","\n","from tqdm.notebook import tqdm\n","\n","tqdm.pandas(desc='Processing Dataframe')\n"]},{"cell_type":"code","execution_count":2,"id":"ee1458f7","metadata":{},"outputs":[],"source":["PATHS = load_yaml('paths')\n","PHOBERT_DATA = PATHS['phobert_base']\n"]},{"cell_type":"markdown","id":"quality-brand","metadata":{"id":"quality-brand"},"source":["# Prepare data and preprocess"]},{"cell_type":"code","execution_count":null,"id":"cdc8a780-3ef4-4e35-9c34-cf3b351079ae","metadata":{"id":"cdc8a780-3ef4-4e35-9c34-cf3b351079ae"},"outputs":[],"source":["df = load_data()\n","df.info()\n"]},{"cell_type":"code","execution_count":null,"id":"395d4cec","metadata":{"id":"395d4cec"},"outputs":[],"source":["df['category'].unique()\n"]},{"cell_type":"code","execution_count":null,"id":"a07d79a8","metadata":{"id":"a07d79a8"},"outputs":[],"source":["def preprocess_data(raw_df, stored_list=None):\n","    raw_df = raw_df.copy()\n","\n","    # drop null value\n","    raw_df.drop(raw_df[(raw_df.category.isnull())\n","                       | raw_df.text.isnull()].index,\n","                axis=0,\n","                inplace=True)\n","\n","    # preprocess text\n","    raw_df['text'] = raw_df['text'].progress_apply(NLP().preprocess_text)\n","\n","    # drop rows that have len(clean_body) < 10\n","    len_texts = raw_df['text'].astype(str).apply(lambda t: len(t.split()))\n","    raw_df.drop(len_texts[len_texts <= 10].index, axis=0, inplace=True)\n","\n","    print(f'preprocess data complete! processed data shape: {raw_df.shape}')\n","    if stored_list is not None:\n","        stored_list.append(raw_df)\n","\n","    return raw_df\n","\n","\n","def multi_preprocess_data(raw_df, n_cores=4):\n","    manager = multiprocessing.Manager()\n","    dfs = manager.list()\n","    jobs = []\n","    offset = int(raw_df.shape[0] / n_cores)\n","    start_index = 0\n","\n","    for i in range(n_cores):\n","        if i == n_cores - 1:\n","            part_df = raw_df.iloc[start_index:, :]\n","        else:\n","            part_df = raw_df.iloc[start_index:start_index + offset, :]\n","\n","        start_index += offset\n","\n","        p = multiprocessing.Process(target=preprocess_data,\n","                                    args=(part_df, dfs))\n","        jobs.append(p)\n","        print(f'Start process {i}')\n","        p.start()\n","\n","    for p in jobs:\n","        p.join()\n","\n","    return pd.concat(dfs, axis=0).reset_index(drop=True)\n"]},{"cell_type":"code","execution_count":null,"id":"c64f7a48","metadata":{"id":"c64f7a48"},"outputs":[],"source":["clean_df = multi_preprocess_data(df, 6)\n","clean_df.info()\n"]},{"cell_type":"code","execution_count":null,"id":"c0912001-1483-4efd-b11e-b91973d9b70b","metadata":{"id":"c0912001-1483-4efd-b11e-b91973d9b70b"},"outputs":[],"source":["clean_df.to_csv('data/data2_keep_stopwords.csv', index=False)\n","clean_df\n"]},{"cell_type":"code","execution_count":3,"id":"8823f37f","metadata":{"id":"8823f37f","outputId":"7a8b447e-552c-438b-9d58-f7c9b3aa2eee"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>category</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>thể thao</td>\n","      <td>một granada xếp áp_chót bảng tất_nhiên không_t...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>thể thao</td>\n","      <td>ở trận này hlv pep guardiola tung ra sân đội_h...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>thể thao</td>\n","      <td>ở trận này tomas berdych đã chơi không tốt vì ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>thể thao</td>\n","      <td>làm thế_nào để có_thể kéo khán_giả đến sân cđv...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>thể thao</td>\n","      <td>môn quần_vợt không đòi_hỏi sức_mạnh quá mức nê...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>141291</th>\n","      <td>155589</td>\n","      <td>kinh doanh</td>\n","      <td>khách_hàng có_thể đặt lịch bảo_dưỡng sửa_chữa ...</td>\n","    </tr>\n","    <tr>\n","      <th>141292</th>\n","      <td>155613</td>\n","      <td>kinh doanh</td>\n","      <td>nhà_sáng_lập tesla đã khởi_động năm 2022 với m...</td>\n","    </tr>\n","    <tr>\n","      <th>141293</th>\n","      <td>155622</td>\n","      <td>kinh doanh</td>\n","      <td>được phát_triển bởi vinbigdata một công_ty côn...</td>\n","    </tr>\n","    <tr>\n","      <th>141294</th>\n","      <td>155623</td>\n","      <td>kinh doanh</td>\n","      <td>các bác tài cho biết rất nóng_lòng được tham_g...</td>\n","    </tr>\n","    <tr>\n","      <th>141295</th>\n","      <td>155626</td>\n","      <td>kinh doanh</td>\n","      <td>sự_kiện sẽ diễn ra cùng thời_điểm tại nhiều th...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>141296 rows × 3 columns</p>\n","</div>"],"text/plain":["            id    category                                               text\n","0            1    thể thao  một granada xếp áp_chót bảng tất_nhiên không_t...\n","1            2    thể thao  ở trận này hlv pep guardiola tung ra sân đội_h...\n","2            3    thể thao  ở trận này tomas berdych đã chơi không tốt vì ...\n","3            4    thể thao  làm thế_nào để có_thể kéo khán_giả đến sân cđv...\n","4            5    thể thao  môn quần_vợt không đòi_hỏi sức_mạnh quá mức nê...\n","...        ...         ...                                                ...\n","141291  155589  kinh doanh  khách_hàng có_thể đặt lịch bảo_dưỡng sửa_chữa ...\n","141292  155613  kinh doanh  nhà_sáng_lập tesla đã khởi_động năm 2022 với m...\n","141293  155622  kinh doanh  được phát_triển bởi vinbigdata một công_ty côn...\n","141294  155623  kinh doanh  các bác tài cho biết rất nóng_lòng được tham_g...\n","141295  155626  kinh doanh  sự_kiện sẽ diễn ra cùng thời_điểm tại nhiều th...\n","\n","[141296 rows x 3 columns]"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["clean_df = pd.read_csv('data/raw_data.csv')\n","clean_df\n"]},{"cell_type":"code","execution_count":5,"id":"99fc91eb","metadata":{},"outputs":[{"data":{"text/plain":["9"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["len(clean_df['category'].unique())\n"]},{"cell_type":"code","execution_count":null,"id":"da39524f-749f-490c-8a76-4b7c0d6b95d3","metadata":{"id":"da39524f-749f-490c-8a76-4b7c0d6b95d3","tags":[]},"outputs":[],"source":["category_count = clean_df.groupby('category')['text'].count().sort_values(\n","    ascending=False)\n","print(category_count)\n","plt.figure(figsize=(18, 12))\n","sns.barplot(x=category_count.index, y=category_count)\n","plt.xticks(rotation=90)\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"id":"f0f68d41-fe26-4137-8f86-6ba430893dc0","metadata":{"id":"f0f68d41-fe26-4137-8f86-6ba430893dc0"},"outputs":[],"source":["lentext_count = clean_df['text'].apply(lambda x: len(x.split()))\n","lentext_count.describe()\n"]},{"cell_type":"code","execution_count":null,"id":"14e8bb8a-4800-494d-940b-1923daef4d47","metadata":{"id":"14e8bb8a-4800-494d-940b-1923daef4d47"},"outputs":[],"source":["sns.boxplot(lentext_count)\n"]},{"cell_type":"code","execution_count":null,"id":"da449c9b-7d45-48af-b845-c7849b98b03b","metadata":{"id":"da449c9b-7d45-48af-b845-c7849b98b03b"},"outputs":[],"source":["plt.figure(figsize=(15, 30))\n","wc = WordCloud(max_words=100, width=800, height=600)\n","\n","for idx, category in enumerate(labels):\n","    plt.subplot(5, 2, idx + 1)\n","    wc.generate(\" \".join(clean_df.loc[clean_df.category == category, 'text']))\n","    plt.imshow(wc, interpolation='bilinear')\n","    plt.title(category)\n","    plt.axis(\"off\")\n","plt.figure()\n"]},{"cell_type":"markdown","id":"overall-aquarium","metadata":{"id":"overall-aquarium"},"source":["# Training"]},{"cell_type":"code","execution_count":null,"id":"3ed1f1cb","metadata":{"id":"3ed1f1cb"},"outputs":[],"source":["from training import *\n"]},{"cell_type":"markdown","id":"e1f7a8c0","metadata":{"id":"e1f7a8c0"},"source":["### SVM"]},{"cell_type":"code","execution_count":null,"id":"64a2834b-b474-42a4-86d8-1907ddc2f3b5","metadata":{"id":"64a2834b-b474-42a4-86d8-1907ddc2f3b5","outputId":"3fa3061d-65a7-4d07-ce33-739dc9e10914"},"outputs":[{"name":"stdout","output_type":"stream","text":["X_train shape: (110593,)\n","X_test shape:  (27649,)\n","y_train shape:  (110593,)\n","y_test shape:  (27649,)\n"]}],"source":["from sklearn.model_selection import train_test_split\n","\n","X_train, X_test, y_train, y_test = train_test_split(\n","    clean_df['text'],\n","    clean_df['category'],\n","    test_size=0.2,\n","    stratify=clean_df['category'])\n","print(f'X_train shape: {X_train.shape}')\n","print(f'X_test shape:  {X_test.shape}')\n","print(f'y_train shape:  {y_train.shape}')\n","print(f'y_test shape:  {y_test.shape}')\n"]},{"cell_type":"code","execution_count":null,"id":"709cff09","metadata":{"id":"709cff09"},"outputs":[],"source":["clf = svm_straing(X_train, y_train)\n"]},{"cell_type":"code","execution_count":null,"id":"e124413c","metadata":{"id":"e124413c"},"outputs":[],"source":["from sklearn.metrics import classification_report\n","\n","y_pred = clf.predict(X_test)\n","with open('data/classification_report.txt', 'a') as f:\n","    report = classification_report(y_test, y_pred)\n","    f.write(report)\n","    f.write('=' * 53 + '\\n')\n"]},{"cell_type":"code","execution_count":3,"id":"c075b8ec","metadata":{},"outputs":[],"source":["with open('data/model.pickle', 'rb') as f:\n","    clf = pickle.load(f)\n"]},{"cell_type":"code","execution_count":10,"id":"1ed079f3","metadata":{},"outputs":[{"data":{"text/plain":["'Theo BS Trương Hữu Khanh, Cố vấn chuyên môn Khoa Nhiễm Khuẩn - thần kinh, Bệnh viện Nhi đồng 1, TP.HCM, xuất hiện các triệu chứng mệt mỏi, khó thở, đau đầu…sau khi khỏi Covid-19, không phải đều là do hậu Covid-19. Chỉ một số người thực sự mắc di chứng sau khi khỏi bệnh, còn lại là dấu hiệu của các bệnh lý khác nhưng bị nhầm lẫn thành bất thường hậu Covid-19.\\n\\n“Một số dấu hiệu không phải hậu Covid-19 mà là bệnh khác. Ví dụ có trường hợp trẻ sốt, người nhà đinh ninh là hậu Covid nhưng thực ra lại là sốt xuất huyết.\\n\\nNgười khó thở cũng bị suy luận là hậu Covid nhưng thực chất lại là hen suyễn. Có trường hợp ho nhiều, họ tưởng nhầm là di chứng của Covid nhưng đi khám mới phát hiện ra bị bệnh lao. Vì vậy chúng ta phải lưu ý, phòng trường hợp chỉ chăm chăm lo hậu Covid, bỏ sót các bệnh khác, làm bệnh nặng thêm”, bác sĩ Khanh nhấn mạnh'"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["with open('data/test.txt', 'r', ) as f:\n","    text = f.read()\n","text\n"]},{"cell_type":"code","execution_count":11,"id":"18595761","metadata":{},"outputs":[{"data":{"text/plain":["array(['sức khỏe'], dtype=object)"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["clf.predict([text])\n"]},{"cell_type":"markdown","id":"2d47da87","metadata":{"id":"2d47da87"},"source":["### Bert"]},{"cell_type":"code","execution_count":3,"id":"e7a7e938","metadata":{"id":"e7a7e938"},"outputs":[{"name":"stderr","output_type":"stream","text":["2022-01-18 02:53:19.206713: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n"]}],"source":["from phobert.train_classifer_keras import load_text, PhoBertTraining\n","from phobert.embeding import Embeding\n","import logging\n","logging.disable(logging.WARNING)\n"]},{"cell_type":"code","execution_count":null,"id":"28a3c9d8","metadata":{"id":"28a3c9d8"},"outputs":[],"source":["ids_train = load_text(X_train.tolist())\n","ids_test = load_text(X_test.tolist())\n","\n","print(len(ids_train))\n","print(len(y_train))\n","print(len(ids_test))\n","print(len(y_test))\n","\n","with open(\"ids_train\", 'wb') as f:\n","    pickle.dump(ids_train, f)\n","with open(\"y_train\", 'wb') as f:\n","    pickle.dump(y_train, f)\n","\n","with open(\"ids_test\", 'wb') as f:\n","    pickle.dump(ids_test, f)\n","with open(\"y_test\", 'wb') as f:\n","    pickle.dump(y_test, f)\n","\n","print(\"LOAD DATA DONE\")\n"]},{"cell_type":"code","execution_count":4,"id":"d9f77e1b","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":412,"status":"ok","timestamp":1642401502317,"user":{"displayName":"Long Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhVMJhKk7_VigZ2kWKxtT_FSssrLz13ITPlt2q2=s64","userId":"04407739074008177889"},"user_tz":-420},"id":"d9f77e1b","outputId":"c74a3ed9-6adc-46ef-ba78-cdc0c225694a"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[   0  405 1058 ...    1    1    2]\n"," [   0   63  200 ... 8141 4481    2]\n"," [   0 5689 5301 ... 4104 2158    2]\n"," ...\n"," [   0   78  210 ...   11  320    2]\n"," [   0  227  400 ...   57 8677    2]\n"," [   0   63  538 ...    6  200    2]]\n","['giáo dục' 'giải trí' 'kinh doanh' 'pháp luật' 'sức khỏe' 'thế giới'\n"," 'thể thao' 'thời sự' 'văn hóa']\n","LOAD DATA FROM FILE DONE\n"]}],"source":["with open(\"data/ids_train\", \"rb\") as f:\n","    ids_train = pickle.load(f)\n","with open(\"data/y_train\", \"rb\") as f:\n","    y_train = pickle.load(f)\n","with open(\"data/ids_test\", \"rb\") as f:\n","    ids_test = pickle.load(f)\n","with open(\"data/y_test\", \"rb\") as f:\n","    y_test = pickle.load(f)\n","\n","with open('data/label_encoder.pickle', 'rb') as f:\n","    le = pickle.load(f)\n","\n","print(ids_train)\n","print(le.classes_)\n","print(\"LOAD DATA FROM FILE DONE\")\n"]},{"cell_type":"code","execution_count":5,"id":"0mBZfb3Ur7pX","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":607,"status":"ok","timestamp":1642401505582,"user":{"displayName":"Long Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhVMJhKk7_VigZ2kWKxtT_FSssrLz13ITPlt2q2=s64","userId":"04407739074008177889"},"user_tz":-420},"id":"0mBZfb3Ur7pX","outputId":"0faff89d-861d-4d98-8798-3b8fa1a84afb"},"outputs":[{"name":"stdout","output_type":"stream","text":["(113036, 256)\n","(28260, 256)\n","(113036,)\n","(28260,)\n"]}],"source":["print(ids_train.shape)\n","print(ids_test.shape)\n","print(y_train.shape)\n","print(y_test.shape)\n"]},{"cell_type":"code","execution_count":6,"id":"4ycBd7uznTJX","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":823},"executionInfo":{"elapsed":5358,"status":"error","timestamp":1642401950236,"user":{"displayName":"Long Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhVMJhKk7_VigZ2kWKxtT_FSssrLz13ITPlt2q2=s64","userId":"04407739074008177889"},"user_tz":-420},"id":"4ycBd7uznTJX","outputId":"1f314632-a3db-4da9-fb19-a39f13e25204"},"outputs":[{"name":"stdout","output_type":"stream","text":["type of all dataset\n","<class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n","==> Make data generator\n","==> Make data generator success\n","train_generator: 220\n","valid_generator: 55\n","Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv1d (Conv1D)              (None, 252, 128)          491648    \n","_________________________________________________________________\n","conv1d_1 (Conv1D)            (None, 250, 64)           24640     \n","_________________________________________________________________\n","global_max_pooling1d (Global (None, 64)                0         \n","_________________________________________________________________\n","dense (Dense)                (None, 32)                2080      \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 9)                 297       \n","=================================================================\n","Total params: 518,665\n","Trainable params: 518,665\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n"]},{"name":"stderr","output_type":"stream","text":["2022-01-18 02:53:39.571419: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n","2022-01-18 02:53:39.571549: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n","2022-01-18 02:53:39.571670: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-01-18 02:53:39.571925: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n","pciBusID: 0000:02:00.0 name: GeForce MX130 computeCapability: 5.0\n","coreClock: 1.189GHz coreCount: 3 deviceMemorySize: 1.96GiB deviceMemoryBandwidth: 37.33GiB/s\n","2022-01-18 02:53:39.571946: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n","2022-01-18 02:53:39.590787: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n","2022-01-18 02:53:39.590920: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n","2022-01-18 02:53:39.601811: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n","2022-01-18 02:53:39.605785: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n","2022-01-18 02:53:39.605909: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcusolver.so.10'; dlerror: libcusolver.so.10: cannot open shared object file: No such file or directory\n","2022-01-18 02:53:39.611202: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n","2022-01-18 02:53:39.613387: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n","2022-01-18 02:53:39.613420: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1757] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n","Skipping registering GPU devices...\n","2022-01-18 02:53:39.613795: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2022-01-18 02:53:39.614342: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n","2022-01-18 02:53:39.614372: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2022-01-18 02:53:39.614379: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      \n","2022-01-18 02:53:39.674260: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.\n","2022-01-18 02:53:39.674288: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.\n","2022-01-18 02:53:39.674317: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1365] Profiler found 1 GPUs\n","2022-01-18 02:53:39.674533: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcupti.so.11.0'; dlerror: libcupti.so.11.0: cannot open shared object file: No such file or directory\n","2022-01-18 02:53:39.674610: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcupti.so'; dlerror: libcupti.so: cannot open shared object file: No such file or directory\n","2022-01-18 02:53:39.674620: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1415] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI could not be loaded or symbol could not be found.\n","2022-01-18 02:53:39.674634: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.\n","2022-01-18 02:53:39.674646: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1496] function cupti_interface_->Finalize()failed with error CUPTI could not be loaded or symbol could not be found.\n","2022-01-18 02:54:43.184337: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 402653184 exceeds 10% of free system memory.\n","2022-01-18 02:54:43.477664: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n","2022-01-18 02:54:43.496934: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 1800000000 Hz\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n"]}],"source":["y_train_encoded = le.transform(y_train)\n","y_test_encoded = le.transform(y_test)\n","\n","emb = Embeding(PHOBERT_DATA)\n","\n","training = PhoBertTraining(ids_train,\n","                           y_train_encoded,\n","                           ids_test,\n","                           y_test_encoded,\n","                           le.classes_)\n","training.make_generator(emb.get_emb_vector, batch_size=512)\n","training.build_model()\n","history = training.fit(n_epochs=10)\n","training.plot_train_history(history)\n"]},{"cell_type":"markdown","id":"cce82965","metadata":{},"source":["## datasets"]},{"cell_type":"code","execution_count":2,"id":"5f33384f","metadata":{},"outputs":[],"source":["from training import PhobertTraining\n"]},{"cell_type":"code","execution_count":3,"id":"eba0ae51","metadata":{},"outputs":[],"source":["training = PhobertTraining('data/phobert-base')\n"]},{"cell_type":"code","execution_count":4,"id":"dac41597","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Using custom data configuration default-31a95d250e5386b0\n","Reusing dataset csv (/home/long/.cache/huggingface/datasets/csv/default-31a95d250e5386b0/0.0.0/6b9057d9e23d9d8a2f05b985917a0da84d70c5dae3d22ddd8a3f22fb01c69d9e)\n","100%|██████████| 1/1 [00:00<00:00, 19.21it/s]\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","Loading cached processed dataset at /home/long/.cache/huggingface/datasets/csv/default-31a95d250e5386b0/0.0.0/6b9057d9e23d9d8a2f05b985917a0da84d70c5dae3d22ddd8a3f22fb01c69d9e/cache-92a22ed49c5f65ac.arrow\n","Loading cached split indices for dataset at /home/long/.cache/huggingface/datasets/csv/default-31a95d250e5386b0/0.0.0/6b9057d9e23d9d8a2f05b985917a0da84d70c5dae3d22ddd8a3f22fb01c69d9e/cache-83c29265ed322875.arrow and /home/long/.cache/huggingface/datasets/csv/default-31a95d250e5386b0/0.0.0/6b9057d9e23d9d8a2f05b985917a0da84d70c5dae3d22ddd8a3f22fb01c69d9e/cache-17c01223bc6acbb1.arrow\n","2022-01-19 09:40:58.907035: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n","2022-01-19 09:40:58.913265: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n","2022-01-19 09:40:58.957060: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-01-19 09:40:58.957669: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n","pciBusID: 0000:02:00.0 name: GeForce MX130 computeCapability: 5.0\n","coreClock: 1.189GHz coreCount: 3 deviceMemorySize: 1.96GiB deviceMemoryBandwidth: 37.33GiB/s\n","2022-01-19 09:40:58.957736: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n","2022-01-19 09:40:58.975152: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n","2022-01-19 09:40:58.975264: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n","2022-01-19 09:40:58.986937: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n","2022-01-19 09:40:58.992406: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n","2022-01-19 09:40:58.992860: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcusolver.so.10'; dlerror: libcusolver.so.10: cannot open shared object file: No such file or directory\n","2022-01-19 09:40:59.000497: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n","2022-01-19 09:40:59.003066: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n","2022-01-19 09:40:59.003117: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1757] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n","Skipping registering GPU devices...\n","2022-01-19 09:40:59.004853: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2022-01-19 09:40:59.006998: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n","2022-01-19 09:40:59.007091: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2022-01-19 09:40:59.007109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      \n","2022-01-19 09:40:59.334448: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 462995456 exceeds 10% of free system memory.\n","2022-01-19 09:41:01.528752: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 462995456 exceeds 10% of free system memory.\n","2022-01-19 09:41:03.804367: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 462995456 exceeds 10% of free system memory.\n","2022-01-19 09:41:05.646301: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 115752960 exceeds 10% of free system memory.\n","2022-01-19 09:41:06.097727: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 115752960 exceeds 10% of free system memory.\n"]},{"name":"stdout","output_type":"stream","text":["train dataset shape: <TensorSliceDataset shapes: ({input_ids: (512,), token_type_ids: (512,), attention_mask: (512,)}, ()), types: ({input_ids: tf.int64, token_type_ids: tf.int64, attention_mask: tf.int64}, tf.int64)>\n","validation dataset shape: <TensorSliceDataset shapes: ({input_ids: (512,), token_type_ids: (512,), attention_mask: (512,)}, ()), types: ({input_ids: tf.int64, token_type_ids: tf.int64, attention_mask: tf.int64}, tf.int64)>\n"]}],"source":["with open('data/training_data/label_encoder.pickle', 'rb') as f:\n","    label_encoder = pickle.load(f)\n","training.make_data('data/raw_data.csv',\n","                   label_encoder=label_encoder,\n","                   test_size=0.2,\n","                   batch_size=2)\n"]},{"cell_type":"code","execution_count":5,"id":"b1414890","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["2022-01-19 09:41:14.724720: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.\n","2022-01-19 09:41:14.724751: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.\n","2022-01-19 09:41:14.725998: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1365] Profiler found 1 GPUs\n","2022-01-19 09:41:14.736743: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcupti.so.11.0'; dlerror: libcupti.so.11.0: cannot open shared object file: No such file or directory\n","2022-01-19 09:41:14.736917: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcupti.so'; dlerror: libcupti.so: cannot open shared object file: No such file or directory\n","2022-01-19 09:41:14.736939: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1415] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI could not be loaded or symbol could not be found.\n","2022-01-19 09:41:14.737249: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.\n","2022-01-19 09:41:14.737283: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1496] function cupti_interface_->Finalize()failed with error CUPTI could not be loaded or symbol could not be found.\n","All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n","\n","Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at data/phobert-base and are newly initialized: ['classifier']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"name":"stdout","output_type":"stream","text":["init model successfully!\n","Model: \"tf_roberta_for_sequence_classification\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","roberta (TFRobertaMainLayer) multiple                  134407680 \n","_________________________________________________________________\n","classifier (TFRobertaClassif multiple                  597513    \n","=================================================================\n","Total params: 135,005,193\n","Trainable params: 597,513\n","Non-trainable params: 134,407,680\n","_________________________________________________________________\n","None\n","Epoch 1/10\n"]},{"name":"stderr","output_type":"stream","text":["2022-01-19 09:41:30.391536: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n","2022-01-19 09:41:30.489728: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 1800000000 Hz\n"]},{"ename":"InvalidArgumentError","evalue":" indices[0,480] = 482 is not in [0, 258)\n\t [[node tf_roberta_for_sequence_classification/roberta/embeddings/Gather_1 (defined at home/long/CodeWorkspace/NLP/venv/lib/python3.8/site-packages/transformers/models/roberta/modeling_tf_roberta.py:167) ]] [Op:__inference_train_function_24407]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node tf_roberta_for_sequence_classification/roberta/embeddings/Gather_1:\n tf_roberta_for_sequence_classification/roberta/embeddings/add_1 (defined at home/long/CodeWorkspace/NLP/venv/lib/python3.8/site-packages/transformers/models/roberta/modeling_tf_roberta.py:129)\n\nFunction call stack:\ntrain_function\n","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_6123/1762964079.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m~/CodeWorkspace/NLP/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, n_epochs, log_dir, checkpoint_dir)\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0;31m# fit the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m         history = self.model.fit(\n\u001b[0m\u001b[1;32m    172\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_tf_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/CodeWorkspace/NLP/venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/CodeWorkspace/NLP/venv/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/CodeWorkspace/NLP/venv/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 888\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    889\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/CodeWorkspace/NLP/venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/CodeWorkspace/NLP/venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n","\u001b[0;32m~/CodeWorkspace/NLP/venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/CodeWorkspace/NLP/venv/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInvalidArgumentError\u001b[0m:  indices[0,480] = 482 is not in [0, 258)\n\t [[node tf_roberta_for_sequence_classification/roberta/embeddings/Gather_1 (defined at home/long/CodeWorkspace/NLP/venv/lib/python3.8/site-packages/transformers/models/roberta/modeling_tf_roberta.py:167) ]] [Op:__inference_train_function_24407]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node tf_roberta_for_sequence_classification/roberta/embeddings/Gather_1:\n tf_roberta_for_sequence_classification/roberta/embeddings/add_1 (defined at home/long/CodeWorkspace/NLP/venv/lib/python3.8/site-packages/transformers/models/roberta/modeling_tf_roberta.py:129)\n\nFunction call stack:\ntrain_function\n"]}],"source":["training.fit()"]}],"metadata":{"accelerator":"TPU","colab":{"collapsed_sections":[],"name":"ArticleClassification.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3.10.0 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.0"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false},"toc-autonumbering":true,"vscode":{"interpreter":{"hash":"a42ccb73e7d9bfdf27e036f1d2b8b681e55fc0743cc5586bc2474d4a60f4b886"}}},"nbformat":4,"nbformat_minor":5}
